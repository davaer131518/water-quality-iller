{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e1e652e-a193-4505-a810-3b6417392994",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "756ec3be-6813-435a-a2ec-255e8c443432",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time as t\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from fake_useragent import UserAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb40f960-d738-43ff-9246-6a984686fed8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8218a530-ebcc-47b4-9992-f29b2c49d495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(A):\n",
    "    rt = []\n",
    "    for i in A:\n",
    "        if isinstance(i,list): rt.extend(flatten(i))\n",
    "        else: rt.append(i)\n",
    "    return rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea44912c-0876-4ab7-a4a1-d2c2a97dfb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniquize(seq):\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    return [x for x in seq if not (x in seen or seen_add(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc7657c3-cff0-4a16-b060-e7693326c6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom aggregation function to calculate the average considering conditions\n",
    "def custom_agg(x):\n",
    "    numeric_values = pd.to_numeric(x, errors='coerce')\n",
    "    if numeric_values.notna().any():\n",
    "        return numeric_values.mean()\n",
    "    elif '< BG' in x.values:\n",
    "        return '< BG'\n",
    "    else:\n",
    "        return pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a58bcdd4-5398-40be-a789-dec2f59b34ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ua = UserAgent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b3bc42-021f-46c0-9739-fbc29a65ba4d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "966d0f8a-23ff-43ce-8cdb-eda6344a2f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_link = 'https://www.gkd.bayern.de/de/fluesse/chemie/iller_lech/kempten-pegel-2290/gesamtzeitraum/tabelle?beginn=07.01.1982&ende=13.12.2021&mpnr1=1600&mpnr2=-1'\n",
    "\n",
    "link_segment = 'https://www.gkd.bayern.de/de/fluesse/chemie/iller_lech/kempten-pegel-2290/gesamtzeitraum/tabelle?beginn=07.01.1982&ende=13.12.2021&zr=gesamt&msprg=0&prbstnr=2290%2C113777&mpnr2=-1&art=Mittel&tab=1&mpnr1='"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b8b11a-362b-402c-bc57-a672fc5b5af1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Link Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcb730ee-d6a8-4926-b152-a22bc412bad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = {'User-Agent':str(ua.random)}\n",
    "content = requests.get(base_link, headers = header)\n",
    "soup = BeautifulSoup(content.content, 'html.parser')\n",
    "\n",
    "feature_values_container = soup.find('select', {'name':'mpnr1'})\n",
    "feature_values_raw = feature_values_container.find_all('option')\n",
    "feature_values = [i['value'] for i in feature_values_raw]\n",
    "\n",
    "all_links = [link_segment + i for i in feature_values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deba9ff-10fa-4137-be45-98937a0b7d9f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ba0a577-5a96-495e-ba34-566221d3eb16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8553f7d7853a4dfd9ae45fa9f9c9d17e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfs = []\n",
    "for link in tqdm(all_links):\n",
    "    header = {'User-Agent':str(ua.random)}\n",
    "    content = requests.get(link, headers = header)\n",
    "    soup = BeautifulSoup(content.content, 'html.parser')\n",
    "    \n",
    "    table_container = soup.find('table')\n",
    "    feature_name_container = table_container.find('th', {'class':'center sorter-numberSorter'})\n",
    "    feature_name = feature_name_container.text.strip()\n",
    "    \n",
    "    data_container = table_container.find('tbody')\n",
    "    data_narrow = data_container.find_all('tr')\n",
    "    data_narrower = [i.find_all('td') for i in data_narrow]\n",
    "    data_dates = [i[0].text.strip() for i in data_narrower]\n",
    "    data_values = [i[1].text.strip().replace('.', '').replace(',', '.') for i in data_narrower]\n",
    "    \n",
    "    data = {'Date': data_dates,\n",
    "            feature_name: data_values}\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df['Date'] = pd.to_datetime(df['Date'], format='%d.%m.%Y')\n",
    "    df_sorted = df.sort_values(by='Date').reset_index(drop=True)\n",
    "    \n",
    "    # Group by month and calculate the average considering conditions\n",
    "    df_grouped = df_sorted.groupby(df_sorted['Date'].dt.to_period(\"M\")).agg({feature_name: custom_agg}).reset_index()\n",
    "\n",
    "    dfs.append(df_grouped)\n",
    "\n",
    "for i in range(len(dfs)):\n",
    "    dfs[i] = dfs[i].drop_duplicates(subset='Date')\n",
    "    \n",
    "result = dfs[0]  \n",
    "for df in dfs[1:]:\n",
    "    result = pd.merge(result, df, on='Date', how='outer')\n",
    "\n",
    "result = result.sort_values(by='Date').reset_index(drop=True)\n",
    "result['Date'] = result['Date'].dt.to_timestamp() + pd.offsets.MonthBegin(0) + pd.to_timedelta('14D')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6589484-4466-4bca-8e86-f1c553648de0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Add Missing Years/Months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0e490ce-713c-4f24-bd31-836d354146ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_25092\\314324886.py:27: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  result_combined = pd.concat([result, missing_indices], sort=False)\n"
     ]
    }
   ],
   "source": [
    "# Generate a range of monthly dates from January 1982 to December 2021\n",
    "start_date = '1982-01-15'\n",
    "end_date = '2021-12-15'\n",
    "date_list = [pd.Timestamp(start_date)]\n",
    "while date_list[-1] + pd.DateOffset(months=1) <= pd.Timestamp(end_date):\n",
    "    date_list.append(date_list[-1] + pd.DateOffset(months=1))\n",
    "\n",
    "# Create a DataFrame with the formatted dates\n",
    "df_monthly_dates = pd.DataFrame({'Date': [date.strftime('%Y-%m-15') for date in date_list]})\n",
    "\n",
    "# Identify columns to be added (excluding 'Date')\n",
    "columns_to_add = result.columns.difference(df_monthly_dates.columns)\n",
    "\n",
    "# Add columns from the original result DataFrame to df_monthly_dates and fill with NaN\n",
    "for col in columns_to_add:\n",
    "    if col != 'Date':\n",
    "        df_monthly_dates[col] = pd.NA\n",
    "\n",
    "result.set_index('Date', inplace=True)\n",
    "df_monthly_dates.set_index('Date', inplace=True)\n",
    "df_monthly_dates.index = pd.to_datetime(df_monthly_dates.index)\n",
    "\n",
    "# Identify missing indices\n",
    "missing_indices = df_monthly_dates[~df_monthly_dates.index.isin(result.index)]\n",
    "\n",
    "# Concatenate only the missing rows to the original result DataFrame\n",
    "result_combined = pd.concat([result, missing_indices], sort=False)\n",
    "result_combined = result_combined.sort_index()\n",
    "\n",
    "# Reset the index to make 'Date' a regular column\n",
    "result_combined = result_combined.reset_index()\n",
    "\n",
    "# Extract only the date part of the 'Date' column\n",
    "result_combined['Date'] = result_combined['Date'].dt.date\n",
    "\n",
    "# Round numeric values to the third decimal place (excluding 'Date')\n",
    "result_combined = result_combined.round({'Date': 0}).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6b225e9-dc72-4c2f-850e-b43aa811f321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round Numbers\n",
    "\n",
    "for col in result_combined.columns:\n",
    "    if col != 'Date':\n",
    "        # Iterate through values in the column\n",
    "        for i in range(len(result_combined[col])):\n",
    "            # Check if the value can be converted to numeric\n",
    "            try:\n",
    "                numeric_value = pd.to_numeric(result_combined.at[i, col], errors='coerce')\n",
    "                if not pd.isna(numeric_value):\n",
    "                    # Round numeric values to the third decimal point\n",
    "                    result_combined.at[i, col] = round(numeric_value, 3)\n",
    "            except (ValueError, TypeError):\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3917eca-dddb-428a-896e-7f84617d0610",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "1eb2262b-e796-432b-847d-8f67fbbbeed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_combined.to_csv('BasisAnalytikMerged.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d298bf31-f0f5-4b8d-ab3b-9a04f7f8a1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('BasisAnalytikMerged.csv', encoding='utf-8', delimiter=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
